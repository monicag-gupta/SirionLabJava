https://kafka.apache.org/downloads

Download the Binary downloads:
Scala 2.12  - kafka_2.12-3.7.1.tgz (asc, sha512)

Extract it and save the folder in a location in drive





Create a Topic:
kafka-topics.sh --create --topic <topic_name> --bootstrap-server <kafka_broker> --partitions <num_partitions> --replication-factor <num_replicas>
List Topics:
kafka-topics.sh --list --bootstrap-server <kafka_broker>
Send Messages:
kafka-console-producer.sh --topic <topic_name> --bootstrap-server <kafka_broker>
Consume Messages:
kafka-console-consumer.sh --topic <topic_name> --bootstrap-server <kafka_broker> --from-beginning






Zookeeper: Starts first and manages Kafka’s distributed coordination.
Kafka Broker: Starts after Zookeeper and manages message storage and retrieval.

Start terminal as sudo / powershell as administrator:
> cd C:\kafka 
> .\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties
$ sudo ./bin/zookeeper-server-start.sh ./config/zookeeper.properties
Minimize it.

Start another terminal as sudo / powershell as administrator:
> cd C:\kafka 
> .\bin\windows\kafka-server-start.bat .\config\server.properties

$ sudo ./bin/kafka-server-start.sh ./config/server.properties

Minimize it




Start terminal as sudo / powershell as administrator:
> cd C:\kafka 
>  .\bin\windows\kafka-topics.bat --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
>>

$ sudo ./bin/kafka-topics.sh --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1


Created topic test-topic.






Create a Project: SBKafkaPrj
Group: SBKafkaPrjGr
Artifact id: SBKafkaPrj
Name : SBKafkaPrj
Package: com.SBKafkaPrj





Components of the project:

Dependencies: Required libraries for Kafka and web functionalities.
Configuration: Kafka settings for producers and consumers.
Producer Service: Sends messages to Kafka.
Consumer Service: Listens and processes messages from Kafka.
Controller: Exposes an API endpoint for sending messages.
Topic Creation: Sets up Kafka topics for message handling.




│   pom.xml
├───src\main\java
│   │   │   └───com\SBKafkaPrj
│   │   │               KafkaConsumerService.java
│   │   │               KafkaController.java
│   │   │               KafkaProducerService.java
│   │   │               SBKafkaPrjApplication.java
│   │   └───resources
│   │       │   application.properties
│   └───test\java
│           └───com\SBKafkaPrj
│                       SbPrjKf12345ApplicationTests.java








spring.application.name=SbPrjKf12345
# Kafka broker address
spring.kafka.bootstrap-servers=localhost:9092

# Producer configuration
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

# Consumer configuration
spring.kafka.consumer.group-id=my-group
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer





This section configures Kafka properties for both the producer and consumer:
spring.kafka.bootstrap-servers: Specifies the address of the Kafka broker. The broker is where the Kafka cluster is running.
Producer Configuration:
key-serializer: Defines how the key of the messages will be serialized (converted to bytes). Here, it is using StringSerializer.
value-serializer: Defines how the value of the messages will be serialized.
Consumer Configuration:
group-id: Specifies the consumer group that will process the messages.
key-deserializer: Defines how the key of the messages will be deserialized (converted from bytes to an object).
value-deserializer: Defines how the value of the messages will be deserialized.








package com.SbPrjKf12345;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;

@Service
public class KafkaProducerService {
    private final KafkaTemplate<String, String> kafkaTemplate;

    @Autowired
    public KafkaProducerService(KafkaTemplate<String, String> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    public void sendMessage(String topic, String message) {
        kafkaTemplate.send(topic, message);
    }
}






The KafkaProducerService class is responsible for sending messages to Kafka topics:

KafkaTemplate<String, String>: Provides methods to send messages to Kafka topics. The type parameters (String, String) denote that both the key and value of the messages are strings.

sendMessage: Method to send a message to a specified topic. It uses the KafkaTemplate to publish messages.








package com.SbPrjKf12345;

import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Service;

@Service
public class KafkaConsumerService {
    private String msg;
    @KafkaListener(topics = "test-topic", groupId = "my-group")
    public void listen(String message) {
        msg=message;
        System.out.println("Received message: " + message);
    }
public String listenMsg() {
        return msg;
    }

}












The KafkaConsumerService class listens for messages from Kafka topics:

@KafkaListener: Annotation used to define a method that listens to messages from a Kafka topic. Here, it listens to the topic named test-topic and processes messages with a group ID of my-group.

listen: Method that receives and processes messages. In this example, it simply prints the received message.













package com.SbPrjKf12345;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

@RestController
public class KafkaController {
    // @Autowired
    private final KafkaProducerService kafkaProducerService;
    @Autowired
    public KafkaController(KafkaProducerService kafkaProducerService) {
        this.kafkaProducerService = kafkaProducerService;
    } 
    @GetMapping("/send")
    public String sendMessage(@RequestParam("message") String message) {
        kafkaProducerService.sendMessage("test-topic", message);
        return "Message sent to Kafka topic";
    }
@GetMapping("/receive")
    public String receiveMessage() {
        
        return kafkaConsumerService.listenMsg();
    }
}







The KafkaController exposes an endpoint to send messages to Kafka:

@RestController: Indicates that this class is a REST controller and handles HTTP requests.

@GetMapping("/send"): Maps HTTP GET requests to the /send endpoint.

sendMessage: Method that takes a message parameter from the request and uses KafkaProducerService to send it to the test-topic Kafka topic.







Run as -> Maven clean
Run as -> Maven install
Main class -> Run as -> Java Application

Open postman/browser:

http://localhost:8080/send?message=HelloKafka

Output:
Message sent to Kafka topic


Check the console to get the message received by consumer











